# .github/workflows/crawler.yml
name: WebDriver Crawler

on:
  schedule:
    - cron: '0 1 * * *'  # 每天 UTC 时间 1:00 运行
  workflow_dispatch:      # 也可以手动触发

jobs:
  run-crawler:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      - name: Install dependencies
        run: |
          pip install selenium
          sudo apt-get update
          sudo apt-get install -y chromium-chromedriver
          sudo ln -s /usr/lib/chromium-browser/chromedriver /usr/bin/chromedriver
      - name: Run the crawler
        run: python src/update_songs.py


      # 确认是否有文件变动
      - name: Check for changes
        run: |
          git diff --exit-code src/assets/songs_list.json src/assets/songs.json || echo "Changes detected"

      # 将更新后的 cards.json 文件提交到 GitHub
      - name: Commit updated songs_list.json
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git add src/assets/cards.json
          git status # 查看是否有变更
          git diff --exit-code src/assets/songs_list.json src/assets/songs.json || (git commit -m "Update songs_list.json" && git push)
