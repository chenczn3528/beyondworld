# -*- coding: utf-8 -*-
"""
ä¸–ç•Œä¹‹å¤–WIKI ä¾§å½±å¡ç‰‡æŠ“å–
- åˆè§„ UAã€Session+Retryã€ç¤¼è²Œé™é€Ÿ
- ä»…ä¿å­˜å›¾ç‰‡/è§†é¢‘é“¾æ¥ï¼Œä¸ä¸‹è½½æ–‡ä»¶
- æ¨¡æ¿è§£ææ›´é²æ£’ï¼›å­—æ®µæ¸…æ´—
"""

import json
import time
import random
import re
from typing import Dict, List

import requests
import mwclient
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# -----------------------------
# åŸºæœ¬é…ç½®
# -----------------------------
BASE_URL = "https://wiki.biligame.com"
WIKI_PATH = "/world/"
LIST_URL = f"{BASE_URL}{WIKI_PATH}%E4%BE%A7%E5%BD%B1%E5%9B%BE%E9%89%B4"

UA = "GachaLabCrawler/1.0 (+mailto:chenczn3528@gmail.com)"
HEADERS = {"User-Agent": UA}

# è¾“å‡º
CARDS_JSON_PATH = "src/assets/cards.json"
POOL_CATEGORIES_PATH = "src/assets/poolCategories.json"

# -----------------------------
# ä¼šè¯ & ç¤¼è²Œè®¿é—®
# -----------------------------
session = requests.Session()
retries = Retry(
    total=5,
    backoff_factor=1.4,
    status_forcelist=[429, 500, 502, 503, 504],
    allowed_methods=["GET"],
    raise_on_status=False,
)
session.mount("https://", HTTPAdapter(max_retries=retries))
session.headers.update(HEADERS)

def polite_get(url: str, timeout: int = 20) -> requests.Response:
    time.sleep(1.5 + random.random())  # 1.5~2.5s
    resp = session.get(url, timeout=timeout)
    resp.raise_for_status()
    if not resp.encoding:
        resp.encoding = resp.apparent_encoding or "utf-8"
    return resp

# -----------------------------
# å·¥å…·å‡½æ•°
# -----------------------------
def parse_best_from_srcset(srcset: str) -> str:
    """ä¼˜å…ˆè¿”å› 2xï¼Œæ²¡æœ‰åˆ™å–æœ€åä¸€é¡¹ã€‚"""
    if not srcset:
        return ""
    parts = [p.strip() for p in srcset.split(",") if p.strip()]
    if not parts:
        return ""
    for part in reversed(parts):
        if part.endswith(" 2x") or part.endswith("2x"):
            return part.rsplit(" ", 1)[0]
    return parts[-1].rsplit(" ", 1)[0] if " " in parts[-1] else parts[-1]

def clean_kv(line: str):
    """æ¸…æ´—æ¨¡æ¿è¡Œï¼Œè¿”å› (key, value)ï¼›ä¸åˆè§„è¿”å›(None, None)"""
    if "=" not in line:
        return None, None
    k, v = line.split("=", 1)
    k = k.replace("|", "").strip()
    v = v.strip()
    if not k:
        return None, None
    return k, v

# -----------------------------
# mwclient åˆå§‹åŒ–
# -----------------------------
site = mwclient.Site(host="wiki.biligame.com", path=WIKI_PATH, clients_useragent=UA)

# -----------------------------
# è§£æè¯¦æƒ…é¡µçš„å›¾ç‰‡ä¿¡æ¯ï¼ˆä»…é“¾æ¥ï¼‰
# -----------------------------
def extract_image_info_from_detail(detail_url: str) -> List[Dict[str, str]]:
    """ä»è¯¦æƒ…é¡µæå–å‰å‡ ä¸ªçº¯å›¾ç‰‡tabçš„ src / srcset é“¾æ¥"""
    image_info = []
    max_retries = 5
    for attempt in range(max_retries):
        try:
            detail_resp = polite_get(detail_url, timeout=30)
            soup = BeautifulSoup(detail_resp.text, "html.parser")

            resp_tabs = soup.select(".resp-tabs-container .resp-tab-content")

            def is_pure_img_tab(tab):
                element_children = [c for c in tab.children if getattr(c, "name", None)]
                return len(element_children) == 1 and element_children[0].name == "img"

            pure_tabs = [t for t in resp_tabs if is_pure_img_tab(t)]
            for tab in pure_tabs:
                img = tab.find("img")
                if not img:
                    continue
                src = img.get("src") or ""
                srcset = img.get("srcset") or ""
                src_1x = parse_best_from_srcset(srcset) or src
                # å°½é‡ä¿ç•™ä¸¤æ¡£
                parts = [p.strip() for p in (srcset or "").split(",") if p.strip()]
                src_2x = ""
                for part in reversed(parts):
                    if part.endswith(" 2x") or part.endswith("2x"):
                        src_2x = part.rsplit(" ", 1)[0]
                        break
                image_info.append({
                    "src": src,
                    "srcset": src_1x,
                    "srcset2": src_2x
                })
            break
        except Exception as e:
            print(f"æŠ“å–è¯¦æƒ…é¡µå¤±è´¥ï¼š{detail_url} -> {e}", flush=True)
            if attempt < max_retries - 1:
                time.sleep(2)
            else:
                print(f"å·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè·³è¿‡ï¼š{detail_url}", flush=True)
    return image_info

# -----------------------------
# ç”¨ wiki API è·å–å…¶ä»–è¯¦ç»†ä¿¡æ¯
# -----------------------------
def wiki_detailed_info(card_name: str) -> Dict[str, str]:
    """
    ä»é¡µé¢æ–‡æœ¬ä¸­è§£æ {{ä¾§å½± ...}} æ¨¡æ¿ç›¸å…³å­—æ®µ
    - å…¼å®¹é”®æ˜ å°„
    - å®‰å…¨åˆ†æ®µï¼ˆç¼ºæ®µä¸æŠ¥é”™ï¼‰
    """
    info: Dict[str, any] = {}
    try:
        page = site.pages[card_name]
        raw = page.text() or ""
    except Exception as e:
        print(f"[mwclient] è¯»å–å¤±è´¥ï¼š{card_name} -> {e}", flush=True)
        return info

    # ä»¥ '{{ä¾§å½±' åˆ‡å‰²ï¼Œå¯èƒ½å¾—åˆ° [å‰ç½®, åŸºç¡€å­—æ®µæ®µ, ç›¸ä¼šäº‹ä»¶æ®µ, ...]
    parts = raw.split("{{ä¾§å½±")
    if len(parts) < 2:
        return info

    # å­—æ®µåæ˜ å°„
    dict_map = {
        "åç§°": "å¡å",
        "è§’è‰²": "ä¸»è§’",
        "é™å®š": "æ¿å—",
        "ä¸–ç•Œåˆ†ç±»": "ä¸–ç•Œ",
        "è·å–é€”å¾„": "æ¥æº",
        "æ¥æº": "è·å–é€”å¾„",
        "ä¸»å±æ€§": "å±æ€§",
    }

    # åŸºç¡€å­—æ®µæ®µ
    base_block = parts[1]
    for line in base_block.split("\n"):
        k, v = clean_kv(line)
        if not k:
            continue
        if k in dict_map:
            k = dict_map[k]
        info[k] = v

    # â€œç›¸ä¼šäº‹ä»¶â€æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    meets: List[Dict[str, str]] = []
    # å¯èƒ½ parts[2] æ‰æ˜¯ç›¸ä¼šäº‹ä»¶ï¼Œä¹Ÿå¯èƒ½æ›´å¤šæ®µï¼Œè¿™é‡Œä¿é™©æšä¸¾åç»­æ®µ
    for blk in parts[2:]:
        for line in blk.split("\n"):
            k, v = clean_kv(line)
            if not k:
                continue
            # è·³è¿‡â€œç¨€æœ‰åº¦â€è¿™ç±»éäº‹ä»¶å­—æ®µ
            if "ç¨€æœ‰åº¦" in k:
                continue
            if "ç›¸ä¼šäº‹ä»¶" in k:
                if v:
                    meets.append({"title_img": k, "content_html": v})
            else:
                # å…¶ä»–é”®å€¼ä¹Ÿè®°å½•
                info[k] = v
    if meets:
        info["ç›¸ä¼šäº‹ä»¶"] = meets

    return info

# -----------------------------
# è§„èŒƒåŒ–æ•°æ®
# -----------------------------
def check_cards(card: Dict[str, any]) -> Dict[str, any]:
    """ä¸šåŠ¡ä¸Šçš„å°ä¿®æ­£"""
    if card.get("è·å–é€”å¾„") == "ã€ç¾¤æ˜Ÿå¯æ˜æ—¶ã€‘ä¸–ç•Œä¹‹é—´":
        card["è·å–é€”å¾„"] = "ä¸–ç•Œä¹‹é—´"
    return card

def extract_recharge_cards(cards: List[Dict[str, any]]) -> List[Dict[str, str]]:
    """ç”Ÿæˆç´¯å……å¡æ± ä¿¡æ¯"""
    recharge_cards: List[Dict[str, str]] = []

    for card in cards:
        source = card.get("æ¥æº") or ""
        pool_name = card.get("è·å–é€”å¾„") or ""
        if "ç´¯å……" not in source and "ç´¯å……" not in pool_name:
            continue
        recharge_cards.append({
            "name": card.get("å¡å", ""),
            "pool": pool_name or source,
            "rarity": card.get("ç¨€æœ‰åº¦", "")
        })

    def sort_key(entry: Dict[str, str]):
        pool = entry.get("pool", "")
        match = re.search(r"\d+", pool)
        number = int(match.group()) if match else 0
        return (number, pool, entry.get("name", ""))

    recharge_cards.sort(key=sort_key)
    return recharge_cards

def sync_recharge_section(pool_categories: Dict[str, any], recharge_cards: List[Dict[str, str]]) -> bool:
    """å°†ç´¯å……å¡æ± å†™å…¥ poolCategories.jsonï¼Œè¿”å›æ˜¯å¦å‘ç”Ÿå˜æ›´"""
    if "recharge" not in pool_categories:
        pool_categories["recharge"] = {
            "name": "ç´¯å……å¡æ± ",
            "icon": "ğŸ’",
            "cards": []
        }
        changed = True
    else:
        changed = False

    recharge_section = pool_categories["recharge"]
    if "name" not in recharge_section:
        recharge_section["name"] = "ç´¯å……å¡æ± "
        changed = True
    if "icon" not in recharge_section:
        recharge_section["icon"] = "ğŸ’"
        changed = True

    existing_cards = recharge_section.get("cards", [])
    if existing_cards != recharge_cards:
        recharge_section["cards"] = recharge_cards
        changed = True

    return changed

# -----------------------------
# ä¸»æµç¨‹ï¼šåˆ—è¡¨é¡µ -> æ¯é¡¹è¯¦æƒ… -> ç»„è£…è¾“å‡º
# -----------------------------
def main():
    print("ğŸš€ å¼€å§‹æŠ“å–ï¼š", LIST_URL)
    cards: List[Dict[str, any]] = []

    resp = polite_get(LIST_URL)
    soup = BeautifulSoup(resp.text, "html.parser")
    rows = soup.find_all("tr")
    valid_rows: List[tuple] = []

    for row in rows:
        if not row.has_attr("data-param1"):
            continue

        name_div = row.find("div", class_="cardname")
        if not name_div:
            continue
        card_name = name_div.get_text(strip=True).split("Â·")[-1]
        valid_rows.append((row, card_name))

    print(f"ğŸƒ æœ¬æ¬¡å…±éœ€æŠ“å– {len(valid_rows)} å¼ å¡ç‰‡ã€‚", flush=True)

    for index, (row, card_name) in enumerate(valid_rows):

        info_dict = wiki_detailed_info(card_name)

        link_tag = row.find("a", href=True)
        if link_tag:
            detail_url = urljoin(BASE_URL, link_tag["href"])
            print(f"[{index}] æŠ“å–ï¼š{card_name} -> {detail_url}", flush=True)

            image_info = extract_image_info_from_detail(detail_url)
            if image_info:
                info_dict["å›¾ç‰‡ä¿¡æ¯"] = image_info

        info_dict = check_cards(info_dict)

        cards.append(info_dict)

    # ------------ å¡æ± åˆ†ç±»æ›´æ–° ------------
    try:
        with open(POOL_CATEGORIES_PATH, "r", encoding="utf-8") as f:
            pool_categories = json.load(f)
    except FileNotFoundError:
        pool_categories = {}

    existing_pools = set()
    limited_filtered = False

    world_between = pool_categories.get("worldBetween", {})
    subcategories = world_between.get("subcategories", {})
    for key, category in subcategories.items():
        pools = category.get("pools", [])
        if key == "limited":
            filtered_pools = [p for p in pools if "ç´¯å……" not in p]
            if len(filtered_pools) != len(pools):
                category["pools"] = filtered_pools
                pools = filtered_pools
                limited_filtered = True
        for pool_name in pools:
            if key == "limited" and "ç´¯å……" in pool_name:
                continue
            existing_pools.add(pool_name)

    for key, value in pool_categories.items():
        if key == "worldBetween":
            continue
        pools = value.get("pools")
        if isinstance(pools, list):
            for pool_name in pools:
                existing_pools.add(pool_name)

    new_pool_candidates = {}
    for card in cards:
        pool_name = card.get("è·å–é€”å¾„")
        if not pool_name:
            continue
        if "ç´¯å……" in pool_name:
            continue
        if pool_name in existing_pools:
            continue
        if pool_name not in new_pool_candidates:
            new_pool_candidates[pool_name] = card

    newly_added_pools = []

    if new_pool_candidates:
        world_between = pool_categories.setdefault("worldBetween", {
            "name": "ä¸–ç•Œä¹‹é—´ç³»åˆ—",
            "icon": "ğŸŒŸ",
            "subcategories": {}
        })
        subcategories = world_between.setdefault("subcategories", {})

        collapsed_category = subcategories.setdefault("collapsed", {
            "name": "å´©åç³»åˆ—",
            "pools": []
        })
        birthday_category = subcategories.setdefault("birthday", {
            "name": "ç”Ÿæ—¥ç³»åˆ—",
            "pools": []
        })
        limited_category = subcategories.setdefault("limited", {
            "name": "é™å®š",
            "pools": []
        })

        collapsed_pools = collapsed_category.setdefault("pools", [])
        birthday_pools = birthday_category.setdefault("pools", [])
        limited_pools = limited_category.setdefault("pools", [])

        for pool_name, card in new_pool_candidates.items():
            target_list = None
            if card.get("æ‰€å±ä¸–ç•Œ") == "å´©åä¹‹ç•Œ":
                target_list = collapsed_pools
            elif card.get("æ¿å—") == "ç‰¹åˆ«çºªå¿µ":
                target_list = birthday_pools
            else:
                if "æ´»åŠ¨" in pool_name or "å¥‡é‡" in pool_name:
                    continue
                target_list = limited_pools

            if target_list is not None and pool_name not in target_list:
                target_list.append(pool_name)
                newly_added_pools.append(pool_name)
                existing_pools.add(pool_name)

    recharge_cards = extract_recharge_cards(cards)
    recharge_updated = sync_recharge_section(pool_categories, recharge_cards)

    if newly_added_pools or recharge_updated or limited_filtered:
        with open(POOL_CATEGORIES_PATH, "w", encoding="utf-8") as f:
            json.dump(pool_categories, f, ensure_ascii=False, indent=2)
        messages = []
        if newly_added_pools:
            messages.append(f"æ£€æµ‹åˆ°æ–°çš„å¡æ± å¹¶å·²æ›´æ–°: {', '.join(newly_added_pools)}")
        if recharge_updated:
            messages.append("ç´¯å……å¡æ± ä¿¡æ¯å·²åŒæ­¥")
        if limited_filtered:
            messages.append("é™å®šå¡æ± å·²è¿‡æ»¤ç´¯å……å¥–åŠ±")
        print("ï¼›".join(messages), flush=True)
    else:
        print("æœªæ£€æµ‹åˆ°æ–°çš„å¡æ± ï¼Œç´¯å……å¡æ± ä¸é™å®šå¡æ± å‡æ— å˜åŒ–ã€‚", flush=True)

    # ------------ ä¿å­˜å¡ç‰‡æ•°æ® ------------
    with open(CARDS_JSON_PATH, "w", encoding="utf-8") as f:
        json.dump(cards, f, ensure_ascii=False, indent=2)
    print(f"âœ… å…±æŠ“å– {len(cards)} å¼ å¡ç‰‡ä¿¡æ¯å¹¶ä¿å­˜å®Œæˆã€‚", flush=True)

if __name__ == "__main__":
    main()
